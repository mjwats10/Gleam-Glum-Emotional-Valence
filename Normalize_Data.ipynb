{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# load data\n",
    "eee_root_dir = \"C:\\Capstone\\Exp2 Facial Movements Individual Datafiles\\[eee]\"\n",
    "eee_filepaths = os.listdir(eee_root_dir)\n",
    "eee_dataframes = [pd.read_csv(os.path.join(eee_root_dir, path), skiprows=24) for path in eee_filepaths]\n",
    "eee_all = pd.concat(eee_dataframes)\n",
    "\n",
    "ugh_root_dir = \"C:\\Capstone\\Exp2 Facial Movements Individual Datafiles\\[ugh]\"\n",
    "ugh_filepaths = os.listdir(ugh_root_dir)\n",
    "ugh_dataframes = [pd.read_csv(os.path.join(ugh_root_dir, path), skiprows=24) for path in ugh_filepaths]\n",
    "ugh_all = pd.concat(ugh_dataframes)\n",
    "\n",
    "# add label column to each df\n",
    "eee_all.insert(loc=0, column='label', value='[eee]')\n",
    "ugh_all.insert(loc=0, column='label', value='[ugh]')\n",
    "\n",
    "# unify dataframes\n",
    "all_data = pd.concat([eee_all, ugh_all])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "BZsLPYceSekZ",
    "outputId": "6812c810-c92c-441e-b1bc-e2c76bca6551",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "#\n",
    "# # Change the csv file paths as needed\n",
    "# root_dir = \"C:\\Capstone\\Exp2 Facial Movements Individual Datafiles\"\n",
    "# filepaths = os.listdir(root_dir)\n",
    "# dataframes = [pd.read_csv(os.path.join(root_dir, path), skiprows=24) for path in filepaths]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# drop bad rows\n",
    "#dataframes = [df[(df['Respondent Annotations active'].notna()) & (df['feature-x_1'] > 0) & (df['Respondent Annotations active'] != 'Happy; Surprise')] for df in dataframes]\n",
    "all_data = all_data[(all_data['feature-x_1'].notna()) & (all_data['feature-x_1'] > 0)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SAY2v_JnVGe8"
   },
   "source": [
    "# Separate class label column and feature columns\n",
    "# x_feature_columns = [x for x in dataframes[0].columns if 'feature-x' in x]\n",
    "# y_feature_columns = [x for x in dataframes[0].columns if 'feature-y' in x]\n",
    "x_feature_columns = [x for x in all_data.columns if 'feature-x' in x]\n",
    "y_feature_columns = [x for x in all_data.columns if 'feature-y' in x]\n",
    "\n",
    "# x_features = [df[x_feature_columns] for df in dataframes]\n",
    "# y_features = [df[y_feature_columns] for df in dataframes]\n",
    "#labels = [df['Respondent Annotations active'] for df in dataframes]\n",
    "x_features = all_data[x_feature_columns]\n",
    "y_features = all_data[y_feature_columns]\n",
    "labels = all_data['label']"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "omhEGP_eICnQ"
   },
   "source": [
    "# Converting Pandas dataframes to Numpy nd-arrays\n",
    "# x_arrays = [df.values for df in x_features]\n",
    "# y_arrays = [df.values for df in y_features]\n",
    "#label_columns = [df.values for df in labels]\n",
    "x_array = x_features.values\n",
    "y_array = y_features.values\n",
    "label_column = labels.values"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SqPFSPjbIlaU"
   },
   "source": [
    "# Normalize each row in feature arrays, then concatenate x and y columns\n",
    "# x_arrays = [array - np.mean(array, axis=1, keepdims=True) for array in x_arrays]\n",
    "# y_arrays = [array - np.mean(array, axis=1, keepdims=True) for array in y_arrays]\n",
    "# feature_arrays = [np.concatenate((xy[0], xy[1]), axis=1) for xy in zip(x_arrays, y_arrays)]\n",
    "x_array = x_array - np.mean(x_array, axis=1, keepdims=True)\n",
    "y_array = y_array - np.mean(y_array, axis=1, keepdims=True)\n",
    "feature_array = np.concatenate((x_array, y_array), axis=1)\n",
    "\n",
    "# Calculate mean and stdev vectors for each column in feature arrays\n",
    "# feature_means = [np.mean(array, axis=0, keepdims=True) for array in feature_arrays]\n",
    "# feature_stdev = [np.std(array, axis=0) for array in feature_arrays]\n",
    "feature_means = np.mean(feature_array, axis=0, keepdims=True)\n",
    "feature_stdev = np.std(feature_array, axis=0)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-V3H_Am4L4Fn"
   },
   "source": [
    "# Normalize each column in feature arrays\n",
    "# feature_arrays = [(triple[0] - triple[1]) / triple[2] for triple in zip(feature_arrays, feature_means, feature_stdev)]\n",
    "feature_array = (feature_array - feature_means) / feature_stdev\n",
    "\n",
    "# Concatenate normalized feature arrays with label columns\n",
    "# label_columns = [np.expand_dims(column, axis=1) for column in label_columns]\n",
    "# complete_datasets = [np.concatenate(pair, axis=1) for pair in zip(label_columns, feature_arrays)]\n",
    "label_column = np.expand_dims(label_column, axis=1)\n",
    "complete_dataset = np.concatenate((label_column, feature_array), axis=1)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Convert to dataframe and save to csv\n",
    "save_dir = \"C:\\Capstone\\Exp 2 Normalized\"\n",
    "# save_paths = [os.path.join(save_dir, path) for path in filepaths]\n",
    "# dfs = [pd.DataFrame(array, columns=['label']+x_feature_columns+y_feature_columns) for array in complete_datasets]\n",
    "# for pair in zip(dfs, save_paths):\n",
    "#     pair[0].to_csv(pair[1], index=False)\n",
    "save_path = os.path.join(save_dir, \"all_data.csv\")\n",
    "all_data = pd.DataFrame(complete_dataset, columns=['label']+x_feature_columns+y_feature_columns)\n",
    "all_data.to_csv(save_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
